{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, datetime, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from collections import Counter\n",
    "\n",
    "# Load utility files\n",
    "attr_names = pickle.load(open('attr_names.pkl', 'rb'))\n",
    "name2attr = pickle.load(open('name_to_attr.pkl', 'rb'))\n",
    "\n",
    "scene_hierarchy = pd.read_csv('places_scene_hierarchy.csv', header=1)\n",
    "scene_names = []\n",
    "for sceneid in range(365):\n",
    "    splitted = scene_hierarchy['category'][sceneid].replace('\\'', '').split('/')\n",
    "    scene_names.append(splitted[len(splitted)-1])\n",
    "scene_names = list(scene_hierarchy['category'])\n",
    "\n",
    "tradeoff_convert = {(1, 4), (2, 8), (3, 16), (4, 32), (5, 64)}\n",
    "tradeoff_convert = dict(tradeoff_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "sgroup1_expl = pickle.load(open('commbuildings_towns_explanations_final.pkl', 'rb'))\n",
    "sgroup2_expl = pickle.load(open('home_hotel_explanations_final.pkl', 'rb'))\n",
    "\n",
    "# Adjust the bias term in the explanations\n",
    "K_lst = [4, 8, 16, 32, 64]\n",
    "for K in K_lst:\n",
    "    for sgroup in [sgroup1_expl, sgroup2_expl]:\n",
    "        sgroup[K]['clf'].intercept_ = sgroup[K]['clf'].intercept_ - np.min(sgroup[K]['clf'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results and inputs files\n",
    "data = pickle.load(open('all_results_inputs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which study to analyze\n",
    "study = 'example'; K = 0\n",
    "# study = '8concept'; K = 8\n",
    "# study = '16concept'; K = 16\n",
    "# study = '32concept'; K = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define based on the chosen study\n",
    "results = data[study]['results']\n",
    "inputs =  data[study]['inputs']\n",
    "\n",
    "study_keys = [list(r['output'][0].keys()) for r in results]\n",
    "study_keys = [item for sublist in study_keys for item in sublist]\n",
    "study_keys = set(study_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of concepts used in the explanations\n",
    "if study != 'example':\n",
    "    sgroup1_attr = [s.replace(' ', '') for s in sgroup1_expl[K]['imp_attr']]\n",
    "    sgroup2_attr = [s.replace(' ', '') for s in sgroup2_expl[K]['imp_attr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of explanation coefficients\n",
    "if study != 'example':\n",
    "    coef = {}; coef['sgroup1'] = {}; coef['sgroup2'] = {}\n",
    "    for attr in sgroup1_attr: \n",
    "        coef['sgroup1'][attr] = [0, 0, 0, 0]\n",
    "    for attr in sgroup2_attr:\n",
    "        coef['sgroup2'][attr] = [0, 0, 0, 0]\n",
    "\n",
    "    display = False\n",
    "    \n",
    "    # Loop over scene groups\n",
    "    for g in [1, 2]:\n",
    "        sgroup_expl = sgroup1_expl if g == 1 else sgroup2_expl\n",
    "\n",
    "        # Loop over 4 classes\n",
    "        for optionid in range(4):\n",
    "            cls = sgroup_expl[K]['clf'].classes_[optionid]\n",
    "            if display: print('\\nExplanation for scene class: {} ({})'.format(scene_names[cls], cls))\n",
    "\n",
    "            coefs = sgroup_expl[K]['clf'].coef_[optionid]\n",
    "            coefs_local = []; attrs_local = []\n",
    "            for a in range(112):\n",
    "                if coefs[a] != 0.:\n",
    "                    coefs_local.append(coefs[a])\n",
    "                    attrs_local.append(attr_names[a].replace(' ', ''))\n",
    "            if display: print('{} attributes in total\\n'.format(len(coefs_local)))\n",
    "\n",
    "            # Sort attributes by coefficient magnitude\n",
    "            order = np.argsort(-np.abs(coefs_local))\n",
    "            coefs_local = np.array(coefs_local)[order]\n",
    "            attrs_local = np.array(attrs_local)[order]\n",
    "            for a in range(len(coefs_local)):\n",
    "                if display: print('{:.2f} {}'.format(coefs_local[a], attrs_local[a]))\n",
    "                coef['sgroup{}'.format(g)][attrs_local[a]][optionid] = coefs_local[a]\n",
    "            if display: print('{:.2f}'.format(sgroup_expl[K]['clf'].intercept_[optionid]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary of results\n",
    "float_keys = ['ml_exp', 'subjective_expl', 'subjective', 'subjective2', 'subjective3', 'tradeoff', 'correctcount', 'correctcount2']\n",
    "string_keys = ['reasons', 'descriptions', 'feedback', 'gender', 'gender_written', 'race']\n",
    "\n",
    "print('Varible: (Mean \\u00B1 Standard deviation) [Q1, Q2, Q3]\\n')\n",
    "\n",
    "results_summary = {}\n",
    "for key in float_keys+string_keys:\n",
    "    if key in study_keys:\n",
    "        results_summary[key] = []\n",
    "        for i in range(len(results)):\n",
    "            r = results[i]\n",
    "            if key in float_keys: \n",
    "                if key == 'tradeoff': \n",
    "                    results_summary[key].append(tradeoff_convert[float(r['output'][0][key])])\n",
    "                elif study == '32concept' and key == 'correctcount':\n",
    "                    if i < 25: results_summary[key].append(float(r['output'][0][key]))\n",
    "                elif study == '32concept' and key == 'correctcount2': \n",
    "                    if i >= 25: results_summary[key].append(float(r['output'][0][key]))\n",
    "                else: \n",
    "                    results_summary[key].append(float(r['output'][0][key]))\n",
    "            if key in string_keys:\n",
    "                if r['output'][0][key] != '': results_summary[key].append(r['output'][0][key])\n",
    "\n",
    "        if key in float_keys:        \n",
    "            print('{}: ({:.1f} \\u00B1 {:.1f})'.format(key, np.mean(results_summary[key]), np.std(results_summary[key])), \n",
    "                  np.quantile(results_summary[key], [0.25, 0.5, 0.75]))\n",
    "\n",
    "        if key in string_keys:\n",
    "            print('\\n{}:'.format(key), results_summary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total duration of the study\n",
    "loc = 6 if study == 'example' else 2\n",
    "\n",
    "min_lst = []\n",
    "for i in range(len(results)):\n",
    "    r = results[i]\n",
    "    milisec = r['output'][loc]['timing']['submit'] - r['output'][loc]['timing']['start']\n",
    "    min_lst.append((milisec/1000)/60)\n",
    "print('time per study (minutes) - {} data points'.format(len(min_lst)))\n",
    "print('({:.1f} \\u00B1 {:.1f})'.format(np.mean(min_lst), np.std(min_lst)))\n",
    "print(np.round(np.quantile(np.array(min_lst), [0.25, 0.50, 0.75]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent on each photo\n",
    "sec_lst = []\n",
    "for i in range(len(results)):\n",
    "    r = results[i]\n",
    "    # k = 1, 2, 3, 4\n",
    "    for k in range(1, 5):\n",
    "        if study == '32concept':\n",
    "            if i < 25: sec_lst.append((r['output'][loc]['timing']['nextphoto'][k] - r['output'][loc]['timing']['nextphoto'][k-1])/1000.)\n",
    "            else: sec_lst.append((r['output'][loc]['timing']['nextphoto2'][k] - r['output'][loc]['timing']['nextphoto2'][k-1])/1000.)\n",
    "        else:\n",
    "            sec_lst.append((r['output'][loc]['timing']['nextphoto'][k] - r['output'][loc]['timing']['nextphoto'][k-1])/1000.)\n",
    "            sec_lst.append((r['output'][loc]['timing']['nextphoto2'][k] - r['output'][loc]['timing']['nextphoto2'][k-1])/1000.)\n",
    "    # k = 5\n",
    "    if study == 'example':\n",
    "        sec_lst.append((r['output'][loc]['timing']['pg_task2task2'] - r['output'][loc]['timing']['nextphoto'][4])/1000.)\n",
    "        sec_lst.append((r['output'][loc]['timing']['pg_task22post'] - r['output'][loc]['timing']['nextphoto2'][4])/1000.)\n",
    "    elif study == '32concept':\n",
    "        if i < 25: sec_lst.append((r['output'][2]['timing']['pg_task2agree'] - r['output'][2]['timing']['nextphoto'][4])/1000.)\n",
    "        else: sec_lst.append((r['output'][2]['timing']['pg_task2agree'] - r['output'][2]['timing']['nextphoto2'][4])/1000.)\n",
    "    else:\n",
    "        sec_lst.append((r['output'][loc]['timing']['pg_task2agree'] - r['output'][loc]['timing']['nextphoto'][4])/1000.)\n",
    "        sec_lst.append((r['output'][loc]['timing']['pg_task22agree2'] - r['output'][loc]['timing']['nextphoto2'][4])/1000.)\n",
    "\n",
    "print('time per photo (seconds) - {} data points'.format(len(sec_lst)))\n",
    "print('({:.1f} \\u00B1 {:.1f})'.format(np.mean(sec_lst), np.std(sec_lst)))\n",
    "print(np.round(np.quantile(np.array(sec_lst), [0.25, 0.50, 0.75]), 1))\n",
    "\n",
    "if study == '32concept': sec_person = np.array(sec_lst).reshape((len(results), 5)).mean(1)\n",
    "else: sec_person = np.array(sec_lst).reshape((len(results), 10)).mean(1)\n",
    "print('\\ntime per photo per person (seconds) - {} data points'.format(len(sec_person)))\n",
    "print('({:.1f} \\u00B1 {:.1f})'.format(np.mean(sec_person), np.std(sec_person)))\n",
    "print(np.round(np.quantile(np.array(sec_person), [0.25, 0.50, 0.75]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplicity-correctness tradeoff\n",
    "if study != 'example':\n",
    "    print('percentage of participants who prefer each explanation')\n",
    "    for v in [4, 8, 16, 32, 64]:\n",
    "        print('{} concepts: {:.0f}%'.format(v, np.mean(np.array(results_summary['tradeoff'])==v)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Concept recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg number of concepts recognized per photo\n",
    "if study != 'example':\n",
    "    nconcept_lst = []\n",
    "    for i in range(len(results)):\n",
    "        r = results[i]\n",
    "        if study in ['8concept', '16concept']:\n",
    "            nconcept_lst += [len(a['selected']) for a in r['output'][3]['individual_answers']]\n",
    "            nconcept_lst += [len(a['selected']) for a in r['output'][7]['individual_answers2']]\n",
    "        elif study in ['32concept']:\n",
    "            if i < 25: nconcept_lst += [len(a['selected']) for a in r['output'][3]['individual_answers']]\n",
    "            elif i >= 25: nconcept_lst += [len(a['selected']) for a in r['output'][3]['individual_answers2']]\n",
    "\n",
    "\n",
    "    print('concepts clicked per photo - {} data points'.format(len(nconcept_lst)))\n",
    "    print('({:.1f} \\u00B1 {:.1f})'.format(np.mean(nconcept_lst), np.std(nconcept_lst)))\n",
    "    print(np.quantile(nconcept_lst, [0.25, 0.50, 0.75]))\n",
    "\n",
    "    if study in ['8concept', '16concept']:\n",
    "        nconcept_person = np.array(nconcept_lst).reshape((len(results), 10)).mean(1)\n",
    "    elif study in ['32concept']:\n",
    "        nconcept_person = np.array(nconcept_lst).reshape((len(results), 5)).mean(1)\n",
    "    print('\\nconcepts clicked per photo per person - {} data points'.format(len(nconcept_person)))\n",
    "    print('({:.1f} \\u00B1 {:.1f})'.format(np.mean(nconcept_person), np.std(nconcept_person)))\n",
    "    print(np.round(np.quantile(nconcept_person, [0.25, 0.50, 0.75]), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat results as a dictionary organized by input type\n",
    "if study in ['8concept', '16concept', 'example']:\n",
    "    results_by_inputid = {}\n",
    "    for inputid in range(5):\n",
    "        results_by_inputid[inputid] = []\n",
    "    for i in range(len(results)):\n",
    "        results_by_inputid[results[i]['output'][1]['input']].append(results[i])\n",
    "        \n",
    "elif study in ['32concept']:\n",
    "    results_by_inputid1 = {}; results_by_inputid2 = {}\n",
    "    for inputid in range(5):\n",
    "        results_by_inputid1[inputid] = []\n",
    "        results_by_inputid2[inputid] = []\n",
    "    for i in range(len(results)):\n",
    "        if i < 25: results_by_inputid1[results[i]['output'][1]['input']].append(results[i])\n",
    "        else: results_by_inputid2[results[i]['output'][1]['input']].append(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribute labels for each photo\n",
    "if study != 'example':\n",
    "    attr_targets = {}\n",
    "    for inputid in range(5):\n",
    "        attr_targets[inputid] = {}\n",
    "        attr_targets[inputid]['sgroup1'] = []\n",
    "        attr_targets[inputid]['sgroup2'] = []\n",
    "\n",
    "        for img in inputs[inputid]['input_imagename']:\n",
    "            attr = name2attr['ade20k/'+img]\n",
    "            attr = np.array(attr_names)[attr.astype(np.bool)]\n",
    "            attr = [a.replace(' ', '') for a in attr]\n",
    "            target = set(attr).intersection(sgroup1_attr)\n",
    "            attr_targets[inputid]['sgroup1'].append(target)\n",
    "\n",
    "        for img in inputs[inputid]['input_imagename2']:\n",
    "            attr = name2attr['ade20k/'+img]\n",
    "            attr = np.array(attr_names)[attr.astype(np.bool)]\n",
    "            attr = [a.replace(' ', '') for a in attr]\n",
    "            target = set(attr).intersection(sgroup2_attr)\n",
    "            attr_targets[inputid]['sgroup2'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store performance\n",
    "if study != 'example':\n",
    "    attr_acc = {}; attr_acc['sgroup1'] = {}; attr_acc['sgroup2'] = {}\n",
    "    for attr in sgroup1_attr:\n",
    "        attr_acc['sgroup1'][attr] = {}\n",
    "        attr_acc['sgroup1'][attr]['label'] = np.zeros(5*5)\n",
    "        attr_acc['sgroup1'][attr]['correct'] = np.zeros(5*5)\n",
    "    for attr in sgroup2_attr:\n",
    "        attr_acc['sgroup2'][attr] = {}\n",
    "        attr_acc['sgroup2'][attr]['label'] = np.zeros(5*5)\n",
    "        attr_acc['sgroup2'][attr]['correct'] = np.zeros(5*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate concept recognition performance\n",
    "if study != 'example':\n",
    "    recall1 = []; recall2 = []\n",
    "    precision1 = []; precision2 = []\n",
    "    acc1 = []; acc2 = []\n",
    "    for inputid in range(5):\n",
    "        for personid in range(5):\n",
    "\n",
    "            if study in ['8concept', '16concept']:\n",
    "                r = results_by_inputid[inputid][personid]\n",
    "                selections1 = [a['selected'] for a in r['output'][3]['individual_answers']]\n",
    "                selections2 = [a['selected'] for a in r['output'][7]['individual_answers2']]\n",
    "            elif study in ['32concept']:\n",
    "                r1 = results_by_inputid1[inputid][personid]\n",
    "                r2 = results_by_inputid2[inputid][personid]\n",
    "                selections1 = [a['selected'] for a in r1['output'][3]['individual_answers']]\n",
    "                selections2 = [a['selected'] for a in r2['output'][3]['individual_answers2']]\n",
    "\n",
    "            # Loop over 5 images\n",
    "            for imageid in range(5):\n",
    "\n",
    "                # Sgroup1\n",
    "                target = attr_targets[inputid]['sgroup1'][imageid]\n",
    "                for attr in target:\n",
    "                    attr_acc['sgroup1'][attr]['label'][inputid*5+imageid] = 1\n",
    "\n",
    "                selection = [s.replace('g1_', '') for s in selections1[imageid]]\n",
    "                tp = 0; fp = 0;\n",
    "                for s in selection:\n",
    "                    if s in target: \n",
    "                        tp += 1\n",
    "                        attr_acc['sgroup1'][s]['correct'][inputid*5+imageid] += 1\n",
    "                    else: \n",
    "                        fp += 1\n",
    "                acc1.append(tp/K*100)\n",
    "                recall1.append(tp/len(target)*100)\n",
    "                if tp+fp == 0: precision1.append(np.NaN)\n",
    "                else: precision1.append(tp/(tp+fp)*100)\n",
    "\n",
    "                # Sgroup2\n",
    "                target = attr_targets[inputid]['sgroup2'][imageid]\n",
    "                for attr in target:\n",
    "                    attr_acc['sgroup2'][attr]['label'][inputid*5+imageid] = 1\n",
    "\n",
    "                selection = []\n",
    "                for s in selections2[imageid]:\n",
    "                    selection.append(s.replace('g2_', ''))\n",
    "                tp = 0; fp = 0;\n",
    "                for s in selection:\n",
    "                    if s in target: \n",
    "                        tp += 1\n",
    "                        attr_acc['sgroup2'][s]['correct'][inputid*5+imageid] += 1\n",
    "                    else: \n",
    "                        fp += 1\n",
    "                acc2.append(tp/K*100)\n",
    "                recall2.append(tp/len(target)*100)\n",
    "                if tp+fp == 0: precision2.append(np.NaN)\n",
    "                else: precision2.append(tp/(tp+fp)*100)\n",
    "\n",
    "    print('recall (both):                 {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(recall1+recall2), np.std(recall1+recall2)))\n",
    "    print('recall (1. commbuildings):     {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(recall1), np.std(recall1)))\n",
    "    print('recall (2. home/hotel):        {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(recall2), np.std(recall2)))\n",
    "\n",
    "    print()\n",
    "    print('precision (both):              {:.1f}% \\u00B1 {:.1f}%'.format(np.nanmean(precision1+precision2), np.nanstd(precision1+precision2)))\n",
    "    print('precision (1. commbuildings):  {:.1f}% \\u00B1 {:.1f}%'.format(np.nanmean(precision1), np.nanstd(precision1)))\n",
    "    print('precision (2. home/hotel):     {:.1f}% \\u00B1 {:.1f}%'.format(np.nanmean(precision2), np.nanstd(precision2)))\n",
    "\n",
    "    print()\n",
    "    print('accuracy (both):               {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(acc1+acc2), np.std(acc1+acc2)))\n",
    "    print('accuracy (1. commbuildings):   {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(acc1), np.std(acc1)))\n",
    "    print('accuracy (2. home/hotel):      {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(acc2), np.std(acc2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate individual concept recall\n",
    "if study != 'example':\n",
    "    df = pd.DataFrame(columns=['Group', 'Concepts', 'N_photos', 'Mean and Std', 'Quantile'])\n",
    "    for conceptid in range(K):\n",
    "        attr = sgroup1_attr[conceptid]\n",
    "        recall = attr_acc['sgroup1'][attr]['correct'][attr_acc['sgroup1'][attr]['label'].astype(bool)]/5*100\n",
    "        if len(recall) > 0:\n",
    "            df.loc[conceptid] = ['sgroup1', attr, int(attr_acc['sgroup1'][attr]['label'].sum()), \n",
    "                                 str(np.round(np.mean(recall), 1)) + \" \\u00B1 \" + str(np.round(np.std(recall), 1)),\n",
    "                                 np.quantile(recall, [0.25, 0.5, 0.75])]\n",
    "        else:\n",
    "            df.loc[conceptid] = ['sgroup1', attr, int(attr_acc['sgroup1'][attr]['label'].sum()), '', '']\n",
    "\n",
    "    for conceptid in range(K):\n",
    "        attr = sgroup2_attr[conceptid]\n",
    "        recall = attr_acc['sgroup2'][attr]['correct'][attr_acc['sgroup2'][attr]['label'].astype(bool)]/5*100\n",
    "        if len(recall) > 0:\n",
    "            df.loc[conceptid+K] = ['sgroup2', attr, int(attr_acc['sgroup2'][attr]['label'].sum()), \n",
    "                                   str(np.round(np.mean(recall), 1)) + u\" \\u00B1 \" + str(np.round(np.std(recall), 1)),\n",
    "                                   np.quantile(recall, [0.25, 0.5, 0.75])]\n",
    "        else:\n",
    "            df.loc[conceptid+K] = ['sgroup2', attr, int(attr_acc['sgroup2'][attr]['label'].sum()), '', '']\n",
    "\n",
    "\n",
    "    df.to_csv('concept_recall_{}concept.csv'.format(K))\n",
    "    df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Check explanation score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scores dictionary \n",
    "if study != 'example':\n",
    "    scores = {}\n",
    "    for attr in sgroup1_attr: scores[attr] = 0.\n",
    "    for attr in sgroup2_attr: scores[attr] = 0.\n",
    "\n",
    "    # Check that the recorded explanation scores matches the calculated explanation scores\n",
    "    for inputid in range(5):\n",
    "        for personid in range(5):        \n",
    "\n",
    "            if study in ['8concept', '16concept']:\n",
    "                r = results_by_inputid[inputid][personid]\n",
    "                selections1 = [a['selected'] for a in r['output'][3]['individual_answers']]\n",
    "                selections2 = [a['selected'] for a in r['output'][7]['individual_answers2']]\n",
    "            elif study in ['32concept']:\n",
    "                r1 = results_by_inputid1[inputid][personid]\n",
    "                r2 = results_by_inputid2[inputid][personid]\n",
    "                selections1 = [a['selected'] for a in r1['output'][3]['individual_answers']]\n",
    "                selections2 = [a['selected'] for a in r2['output'][3]['individual_answers2']]\n",
    "\n",
    "            # Loop over images\n",
    "            for imageid in range(5):\n",
    "\n",
    "                # Sgroup1\n",
    "                scores = dict.fromkeys(scores, 0.)\n",
    "                for attr in [s.replace('g1_', '') for s in selections1[imageid]]: \n",
    "                    scores[attr] = 1\n",
    "\n",
    "                if K == 8:\n",
    "                    s1 = -0.12*scores['sidewalk'] + 0.00\n",
    "                    s2 = -1.44*scores['skyscraper'] -1.03*scores['sky'] + 0.69*scores['grass'] -0.23*scores['car'] + 0.23*scores['plant'] + 1.04\n",
    "                    s3 = 1.54*scores['skyscraper'] - 1.11*scores['car'] - 1.04*scores['road'] - 1.00*scores['sidewalk'] -0.75*scores['person'] + 1.04\n",
    "                    s4 = -1.90*scores['skyscraper'] + 0.27*scores['car'] - 0.19*scores['grass'] + 0.04*scores['sidewalk'] + 0.61\n",
    "                if K == 16:\n",
    "                    s1 = 0.89*scores['skyscraper'] + 0.85*scores['flag'] - 0.79*scores['awning'] + 0.59*scores['wall'] + 0.58*scores['car'] + 0.47*scores['trafficlight'] + 0.39*scores['streetlight'] - 0.37*scores['sidewalk'] + 0.27*scores['truck'] + 0.24*scores['sky'] + 0.23*scores['grass'] - 0.12*scores['person'] + 0.09*scores['road'] + 0.04*scores['palm'] + 0.00\n",
    "                    s2 = -3.07*scores['skyscraper'] + 1.64*scores['stairway'] + 1.58*scores['grass'] -1.20*scores['sky'] + 0.78*scores['palm'] + 0.76*scores['plant'] -0.69*scores['truck'] - 0.57*scores['car'] + 0.28*scores['flag'] + 0.26*scores['trafficlight'] - 0.24*scores['streetlight'] + 0.16*scores['sidewalk'] - 0.13*scores['awning'] + 0.08*scores['road'] + 2.40\n",
    "                    s3 = 2.10*scores['skyscraper'] - 2.08*scores['person'] - 1.64*scores['car'] - 1.33*scores['road'] - 1.28*scores['sidewalk'] + 0.22*scores['sky'] - 0.08*scores['streetlight'] - 0.07*scores['wall'] + 2.40\n",
    "                    s4 = - 2.44*scores['skyscraper'] - 1.57*scores['grass'] - 0.80*scores['flag'] + 0.73*scores['road'] - 0.65*scores['trafficlight'] + 0.64*scores['car'] + 0.56*scores['sidewalk'] + 0.53*scores['awning'] - 0.53*scores['plant'] + 0.40*scores['person'] - 0.23*scores['stairway'] - 0.19*scores['wall'] + 0.14*scores['sky'] + 0.56\n",
    "                if K == 32:\n",
    "                    s1 = 1.15*scores['flag'] + 1.12*scores['skyscraper'] - 0.99*scores['awning'] + 0.86*scores['earth'] + 0.83*scores['floor'] + 0.80*scores['car'] - 0.76*scores['pot'] + 0.63*scores['tradename'] + 0.57*scores['trafficlight'] + 0.55*scores['wall'] + 0.55*scores['streetlight'] - 0.53*scores['sidewalk'] + 0.51*scores['stairs'] + 0.50*scores['sky'] + 0.43*scores['truck'] + 0.40*scores['pedestal'] - 0.39*scores['ashcan'] + 0.37*scores['grass'] + 0.32*scores['road'] + 0.32*scores['flowerpot'] + 0.32*scores['tree'] + 0.26*scores['bag'] - 0.26*scores['van'] + 0.26*scores['palm'] + 0.24*scores['bucket'] - 0.19*scores['person'] - 0.04*scores['spotlight'] + 0.00\n",
    "                    s2 = -3.74*scores['skyscraper'] + 2.13*scores['stairway'] + 1.73*scores['grass'] - 1.37*scores['sky'] + 1.26*scores['palm'] - 0.90*scores['truck'] + 0.89*scores['rock'] + 0.89*scores['plant'] - 0.84*scores['box'] - 0.79*scores['car'] - 0.48*scores['flowerpot'] + 0.44*scores['flag'] + 0.40*scores['trafficlight'] - 0.34*scores['streetlight'] + 0.30*scores['road'] - 0.28*scores['van'] - 0.26*scores['mountain'] + 0.20*scores['sidewalk'] - 0.19*scores['spotlight'] - 0.16*scores['awning'] - 0.15*scores['bag'] + 0.13*scores['ashcan'] - 0.07*scores['stairs'] - 0.01*scores['tradename'] + 3.04\n",
    "                    s3 = -2.69*scores['person'] + 2.11*scores['skyscraper'] - 1.71*scores['car'] - 1.42*scores['road'] - 1.41*scores['sidewalk'] + 0.56*scores['sky'] - 0.48*scores['wall'] - 0.31*scores['tree'] - 0.30*scores['streetlight'] - 0.26*scores['flag'] + 3.04\n",
    "                    s4 = -2.73*scores['skyscraper'] - 1.88*scores['grass'] - 1.07*scores['flag'] + 1.01*scores['road'] - 0.92*scores['stairway'] - 0.78*scores['trafficlight'] + 0.69*scores['sidewalk'] + 0.68*scores['car'] + 0.68*scores['awning'] - 0.60*scores['plant'] + 0.48*scores['person'] + 0.41*scores['van'] + 0.40*scores['sky'] - 0.38*scores['palm'] - 0.30*scores['wall'] - 0.23*scores['earth'] + 0.19*scores['spotlight'] - 0.11*scores['tradename'] + 0.07*scores['mountain'] + 0.63\n",
    "\n",
    "                calculated = [s1, s2, s3, s4]\n",
    "                if study in ['8concept', '16concept']: recorded = list(r['output'][6]['finalscores'][imageid].values())\n",
    "                elif study in ['32concept']: recorded = list(r1['output'][6]['finalscores'][imageid].values())\n",
    "                assert calculated == recorded\n",
    "\n",
    "                # Sgroup2\n",
    "                scores = dict.fromkeys(scores, 0.)\n",
    "                for attr in [s.replace('g2_', '') for s in selections2[imageid]]: \n",
    "                    scores[attr] = 1\n",
    "\n",
    "                if K == 8:\n",
    "                    s1 = -0.70*scores['chair'] -0.10*scores['floor'] + 0.08\n",
    "                    s2 = -1.41*scores['bed'] -0.20*scores['cushion'] + 0.16\n",
    "                    s3 = -0.52*scores['windowpane'] -0.33*scores['floor'] -0.04*scores['wall'] + 0.00\n",
    "                    s4 = -1.05*scores['bed'] -0.31*scores['table'] + 0.14*scores['sofa'] + 0.16\n",
    "                if K == 16:\n",
    "                    s1 = 1.88*scores['bed'] - 0.95*scores['chair'] - 0.60*scores['sofa'] - 0.28*scores['armchair'] - 0.04*scores['table'] - 0.03*scores['sconce'] + 0.00\n",
    "                    s2 = -3.20*scores['bed'] + 1.47*scores['chair'] - 1.38*scores['sofa'] - 0.80*scores['cushion'] - 0.39*scores['coffeetable'] - 0.14*scores['armchair'] - 0.14*scores['lamp'] + 1.40\n",
    "                    s3 = 1.36*scores['bed'] - 1.02*scores['windowpane'] - 0.92*scores['wall'] - 0.31*scores['plant'] - 0.24*scores['carpet'] + 0.19*scores['sconce'] - 0.18*scores['floor'] - 0.15*scores['cushion'] - 0.11*scores['vase'] + 1.16\n",
    "                    s4 = 2.00*scores['sofa'] - 1.73*scores['bed'] - 0.88*scores['table'] + 0.68*scores['coffeetable'] - 0.52*scores['chair'] - 0.38*scores['wall'] + 0.30*scores['armchair'] + 0.20*scores['fireplace'] + 0.17*scores['cushion'] + 1.40\n",
    "                if K == 32:\n",
    "                    s1 = 3.57*scores['bed'] - 1.02*scores['sofa'] - 0.97*scores['coffeetable'] - 0.86*scores['chair'] - 0.80*scores['sconce'] + 0.64*scores['windowpane'] - 0.60*scores['armchair'] - 0.60*scores['television'] - 0.58*scores['drinkingglass'] + 0.52*scores['fan'] - 0.42*scores['switch'] + 0.32*scores['cushion'] - 0.28*scores['table'] + 0.26*scores['box'] - 0.25*scores['curtain'] + 0.24*scores['blind'] + 0.23*scores['chestofdrawers'] + 0.12*scores['clock'] - 0.10*scores['telephone'] - 0.01*scores['chandelier'] + 0.00\n",
    "                    s2 = -4.39*scores['bed'] + 2.70*scores['chair'] - 1.98*scores['sofa'] - 1.01*scores['coffeetable'] - 1.00*scores['cushion'] - 0.94*scores['fireplace'] + 0.75*scores['table'] - 0.75*scores['pillow'] - 0.73*scores['armchair'] + 0.65*scores['chandelier'] + 0.46*scores['plate'] - 0.45*scores['clock'] - 0.42*scores['lamp'] - 0.29*scores['curtain'] + 0.22*scores['wallsocket'] - 0.19*scores['ottoman'] - 0.18*scores['book'] - 0.14*scores['television'] - 0.05*scores['sconce'] + 0.01*scores['drinkingglass'] + 2.23\n",
    "                    s3 = 2.20*scores['bed'] - 2.09*scores['wall'] - 1.21*scores['windowpane'] + 0.96*scores['television'] - 0.96*scores['box'] - 0.94*scores['chandelier'] - 0.86*scores['carpet'] - 0.77*scores['plant'] - 0.71*scores['blind'] + 0.69*scores['desk'] + 0.64*scores['sconce'] + 0.50*scores['armchair'] + 0.50*scores['curtain'] + 0.47*scores['telephone'] - 0.46*scores['cushion'] - 0.42*scores['chestofdrawers'] + 0.38*scores['switch'] + 0.29*scores['pillow'] - 0.22*scores['book'] - 0.08*scores['clock'] + 0.07*scores['coffeetable'] - 0.07*scores['wallsocket'] - 0.05*scores['fireplace'] - 0.03*scores['fan'] - 0.03*scores['table'] + 2.68\n",
    "                    s4 = -2.41*scores['bed'] + 2.13*scores['sofa'] + 1.21*scores['fireplace'] + 1.17*scores['coffeetable'] - 1.07*scores['wall'] - 0.98*scores['chair'] - 0.95*scores['table'] + 0.86*scores['cushion'] + 0.83*scores['ottoman'] + 0.75*scores['armchair'] + 0.65*scores['seat'] + 0.49*scores['book'] + 0.28*scores['carpet'] - 0.28*scores['wallsocket'] - 0.28*scores['fan'] - 0.25*scores['chandelier'] - 0.24*scores['plate'] + 0.15*scores['plant'] - 0.11*scores['telephone'] + 0.10*scores['box'] + 0.03*scores['sconce'] + 0.02*scores['windowpane'] + 2.77\n",
    "\n",
    "                calculated = [s1, s2, s3, s4]\n",
    "                if study in ['8concept', '16concept']: recorded = list(r['output'][10]['finalscores2'][imageid].values())\n",
    "                elif study in ['32concept']: recorded = list(r2['output'][6]['finalscores2'][imageid].values())\n",
    "                assert calculated == recorded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Task accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do participants' scene matches with the explanation?\n",
    "match1_lst = []; match2_lst = []\n",
    "maxcorrect1_lst = []; maxcorrect2_lst = []\n",
    "selectedcorrect1_lst = []; selectedcorrect2_lst = []\n",
    "for inputid in range(5):\n",
    "    for personid in range(5):\n",
    "        \n",
    "        if study in ['8concept', '16concept']:\n",
    "            r = results_by_inputid[inputid][personid]\n",
    "            selected1 = [a['predictedclass']-1 for a in r['output'][3]['individual_answers']]\n",
    "            selected2 = [a['predictedclass']-1 for a in r['output'][7]['individual_answers2']]\n",
    "        elif study in ['32concept']:\n",
    "            r1 = results_by_inputid1[inputid][personid]\n",
    "            r2 = results_by_inputid2[inputid][personid]\n",
    "            selected1 = [a['predictedclass']-1 for a in r1['output'][3]['individual_answers']]\n",
    "            selected2 = [a['predictedclass']-1 for a in r2['output'][3]['individual_answers2']]\n",
    "        elif study in ['example']:\n",
    "            r = results_by_inputid[inputid][personid]\n",
    "            selected1 = [a['predictedclass']-1 for a in r['output'][2]['individual_answers']]\n",
    "            selected2 = [a['predictedclass']-1 for a in r['output'][4]['individual_answers2']]\n",
    "   \n",
    "        predicted1 = [i-1 for i in inputs[inputid]['predicted']]\n",
    "        predicted2 = [i-1 for i in inputs[inputid]['predicted2']]\n",
    "        \n",
    "        selectedcorrect1_lst.append(np.mean(np.array(predicted1)==np.array(selected1))*100)\n",
    "        selectedcorrect2_lst.append(np.mean(np.array(predicted2)==np.array(selected2))*100)\n",
    "\n",
    "        if study != 'example':\n",
    "            maxscore1 = []; maxscore2 = []\n",
    "            for imageid in range(5):\n",
    "                if study in ['8concept', '16concept']:\n",
    "                    maxscore1.append(np.argmax(list(r['output'][6]['finalscores'][imageid].values())))\n",
    "                    maxscore2.append(np.argmax(list(r['output'][10]['finalscores2'][imageid].values())))\n",
    "                elif study in ['32concept']:\n",
    "                    maxscore1.append(np.argmax(list(r1['output'][6]['finalscores'][imageid].values())))\n",
    "                    maxscore2.append(np.argmax(list(r2['output'][6]['finalscores2'][imageid].values())))\n",
    "\n",
    "            match1_lst.append(np.mean(np.array(selected1)==np.array(maxscore1))*100)\n",
    "            match2_lst.append(np.mean(np.array(selected2)==np.array(maxscore2))*100)\n",
    "\n",
    "            maxcorrect1_lst.append(np.mean(np.array(predicted1)==np.array(maxscore1))*100)\n",
    "            maxcorrect2_lst.append(np.mean(np.array(predicted2)==np.array(maxscore2))*100)\n",
    "        \n",
    "        \n",
    "print('selected is correct (both):                                {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(selectedcorrect1_lst+selectedcorrect2_lst), \n",
    "                                                                                             np.std(selectedcorrect1_lst+selectedcorrect2_lst)))\n",
    "print('selected is correct (1. commbuildings):                    {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(selectedcorrect1_lst), \n",
    "                                                                                             np.std(selectedcorrect1_lst)))\n",
    "print('selected is correct (2. home/hotel):                       {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(selectedcorrect2_lst), \n",
    "                                                                                             np.std(selectedcorrect2_lst)))\n",
    "\n",
    "if study != 'example':\n",
    "    print()\n",
    "    print('highest score is correct (both):                           {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(maxcorrect1_lst+maxcorrect2_lst), \n",
    "                                                                                                 np.std(maxcorrect1_lst+maxcorrect2_lst)))\n",
    "    print('highest score is correct (1. commbuildings):               {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(maxcorrect1_lst), \n",
    "                                                                                                 np.std(maxcorrect1_lst)))\n",
    "    print('highest score is correct (2. home/hotel):                  {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(maxcorrect2_lst), \n",
    "                                                                                                 np.std(maxcorrect2_lst)))\n",
    "\n",
    "    print()\n",
    "    print('selects explanation with highest score (both):             {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(match1_lst+match2_lst),\n",
    "                                                                                                 np.std(match1_lst+match2_lst)))\n",
    "    print('selects explanation with highest score (1. commbuildings): {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(match1_lst), \n",
    "                                                                                                 np.std(match1_lst)))\n",
    "    print('selects explanation with highest score (1. home/hotel):    {:.1f}% \\u00B1 {:.1f}%'.format(np.mean(match2_lst), \n",
    "                                                                                             np.std(match2_lst)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f835fe87857d871a1833728b429f3cb50e8fd965b55d7b9dce056945b7cf6319"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53627ff",
   "metadata": {},
   "source": [
    "# Checking Probe datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bce259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ade20k_features():\n",
    "    \n",
    "    features = {'train':[], 'val':[], 'test':[]}\n",
    "    attr = {'train':[], 'val':[], 'test':[]}\n",
    "    predictions = {'train':[], 'val':[], 'test':[]}\n",
    "    names = {'train':[], 'val':[], 'test':[]}\n",
    "\n",
    "    A = pickle.load(open('../ADE20k/ade20k_imagelabels_with_texture.pkl', 'rb'))\n",
    "\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_names = A[split]\n",
    "        feat_split = pickle.load(open('../ADE20k/{}_features.pkl'.format(split), 'rb'))\n",
    "        pred_split = pickle.load(open('../ADE20k/{}_scene.pkl'.format(split), 'rb'))\n",
    "        #logit_split = pickle.load(open('../ADE20k/tra'))\n",
    "        for img in img_names:\n",
    "            features[split].append(feat_split[img].squeeze())\n",
    "            predictions[split].append(pred_split[img])\n",
    "            temp = np.zeros(1200)\n",
    "            temp[A['labels'][img]] = 1 \n",
    "            attr[split].append(temp)\n",
    "\n",
    "        features[split] = np.stack(features[split])\n",
    "        predictions[split] = np.array(predictions[split])\n",
    "        attr[split] = np.stack(attr[split])\n",
    "        names[split] = img_names\n",
    "    \n",
    "    return features, attr, predictions, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bce7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pascal_features():\n",
    "    \n",
    "    features = {'train':[], 'val':[], 'test':[]}\n",
    "    attr = {'train':[], 'val':[], 'test':[]}\n",
    "    predictions = {'train':[], 'val':[], 'test':[]}\n",
    "    names = {'train':[], 'val':[], 'test':[]}\n",
    "\n",
    "    A = pickle.load(open('pascal_dataset_split.pkl', 'rb'))\n",
    "    feat_split = pickle.load(open('Pascal/full_features.pkl', 'rb'))\n",
    "    pred_split = pickle.load(open('Pascal/full_scenegroup.pkl', 'rb'))\n",
    "        \n",
    "    path = '../NetDissect-Lite/dataset/broden1_224/images'\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_names = A[split]\n",
    "        #logit_split = pickle.load(open('../ADE20k/tra'))\n",
    "        for img in img_names:\n",
    "            features[split].append(feat_split['{}/{}'.format(path, img)].squeeze())\n",
    "            predictions[split].append(pred_split['{}/{}'.format(path, img)][0])\n",
    "            temp = np.zeros(1200)\n",
    "            temp[A['obj_labels_only'][img]] = 1 \n",
    "            attr[split].append(temp)\n",
    "\n",
    "        features[split] = np.stack(features[split])\n",
    "        predictions[split] = np.array(predictions[split])\n",
    "        attr[split] = np.stack(attr[split])\n",
    "        names[split] = img_names\n",
    "    \n",
    "    return features, attr, predictions, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c92ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_features, ade_attr, ade_predictions, ade_names = get_ade20k_features()\n",
    "pascal_features, pascal_attr, pascal_predictions, pascal_names = get_pascal_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef8d40",
   "metadata": {},
   "source": [
    "## Computing Concept Activation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38625176",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imp_attr = []\n",
    "\n",
    "for at in range(1200):\n",
    "    if pascal_attr['train'][:, at].mean() > 0.02 and ade_attr['train'][:, at].mean() > 0.02:\n",
    "        new_imp_attr.append(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf209c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_search_l2(train_features, train_labels, val_features, val_labels, \n",
    "                      Cs = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]):\n",
    "    best_clf = None\n",
    "    best_auc = 0\n",
    "    \n",
    "    for c in Cs:\n",
    "        clf = LogisticRegression(solver='liblinear', C=c, penalty='l2')\n",
    "        clf.fit(train_features, train_labels)\n",
    "        score = roc_auc_score(val_labels, clf.predict_proba(val_features)[:, 1])\n",
    "        if score>best_auc:\n",
    "            best_auc = score\n",
    "            best_clf = clf\n",
    "            print(score, c)\n",
    "    \n",
    "    return best_clf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f93bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv('../../dataset/broden1_224/label.csv', index_col=0)['name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d057ecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562235332730283 0.001\n",
      "0.9599079951862911 0.005\n",
      "0.9607279800834128 0.01\n",
      "0.9610001520961248 0.05\n",
      "0.9250227755845734 0.001\n",
      "0.9278148935452306 0.005\n",
      "wall\t0.9604064539211602\t0.9279037826199933\n",
      "0.9831079192980495 0.001\n",
      "0.9885788943644299 0.005\n",
      "0.9897492501723206 0.01\n",
      "0.9906500296424388 0.05\n",
      "0.8443003837776164 0.001\n",
      "0.847183902084846 0.005\n",
      "sky\t0.9890929759483067\t0.8339622641509434\n",
      "0.9710759529756943 0.001\n",
      "0.9752193702252335 0.005\n",
      "0.9761585927431513 0.01\n",
      "0.9761963465605246 0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f72acf5e8d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_imp_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     clf = hyperparam_search(ade_features['train'], ade_attr['train'][:, at], \n\u001b[0m\u001b[1;32m      6\u001b[0m                             ade_features['val'], ade_attr['val'][:, at])\n\u001b[1;32m      7\u001b[0m     \u001b[0made_clfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-52f30973cf6c>\u001b[0m in \u001b[0;36mhyperparam_search\u001b[0;34m(train_features, train_labels, val_features, val_labels, Cs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbest_auc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1356\u001b[0m                               \u001b[0;34m\" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                               \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n\u001b[0;32m-> 1358\u001b[0;31m             self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m   1359\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pascal_clfs = []\n",
    "ade_clfs = []\n",
    "\n",
    "for at in new_imp_attr:\n",
    "    clf = hyperparam_search(ade_features['train'], ade_attr['train'][:, at], \n",
    "                            ade_features['val'], ade_attr['val'][:, at])\n",
    "    ade_clfs.append(clf)\n",
    "    ade_score = roc_auc_score(ade_attr['test'][:, at], clf.predict_proba(ade_features['test'])[:, 1])\n",
    "    to_print = [labels[at], ade_score]\n",
    "    \n",
    "    clf = hyperparam_search(pascal_features['train'], pascal_attr['train'][:, at],\n",
    "                           pascal_features['val'], pascal_attr['val'][:, at])\n",
    "    pascal_clfs.append(clf)\n",
    "    pascal_score = roc_auc_score(pascal_attr['test'][:, at], clf.predict_proba(pascal_features['test'])[:, 1])\n",
    "    to_print.append(pascal_score)\n",
    "    print(*to_print, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee97f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall [[0.19992691]]\n",
      "sky [[0.4033036]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4b7fc7799aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_imp_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0made_clfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpascal_clfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i, at in enumerate(new_imp_attr):\n",
    "    print(labels[at], cosine_similarity(ade_clfs[i].coef_, pascal_clfs[i].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b51ecf",
   "metadata": {},
   "source": [
    "## Computing baseline explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5aaf70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_search_l1(train_features, train_labels, val_features, val_labels, \n",
    "                      Cs = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]):\n",
    "    best_clf = None\n",
    "    best_acc = 0\n",
    "    \n",
    "    for c in Cs:\n",
    "        clf = LogisticRegression(solver='liblinear', C=c, penalty='l1')\n",
    "        clf.fit(train_features, train_labels)\n",
    "        score = clf.score(val_features, val_labels)\n",
    "        if score>best_acc:\n",
    "            best_acc = score\n",
    "            best_clf = clf\n",
    "            print(score, c)\n",
    "    \n",
    "    return best_clf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d62b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03242969343805422 0.001\n",
      "0.1233848492525969 0.005\n",
      "0.1603749683303775 0.01\n",
      "0.23714213326577147 0.05\n",
      "0.27514568026349123 0.1\n",
      "0.36711426399797314 0.5\n",
      "0.3701545477577907 1\n",
      "0.3914365340765138\n"
     ]
    }
   ],
   "source": [
    "ade_exp = hyperparam_search_l1(ade_attr['train'], ade_predictions['train'],\n",
    "                              ade_attr['val'], ade_predictions['val'])\n",
    "\n",
    "print(ade_exp.score(ade_attr['test'], ade_predictions['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13233c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_exp = hyperparam_search_l1(pascal_attr['train'], pascal_predictions['train'],\n",
    "                              pascal_attr['val'], pascal_predictions['val'])\n",
    "\n",
    "print(pascal_exp.score(pascal_attr['test'], pascal_predictions['test']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
